---
layout:     post
title:      " CV problems "
subtitle:   " CV problems "
date:       2020-12-04 17:09:00
author:     "DHH"
header-img: "img/bg/leetcodebg.jpg"
catalog: true
tags:
    - 笔试
    - 计算机视觉
typora-root-url: ..\..
---

> “Yeah It's leetcode problem. ”

## 传统图像处理

### 	[sift](https://blog.csdn.net/zddblog/article/details/7521424)

生成高斯差分金字塔,尺度空间构建,空间极值点检测,稳定关键点的精确定位,稳定关键点方向信息分配,关键点描述,特征点匹配。

### 	[surf](https://blog.csdn.net/blateyang/article/details/76512398)

### 	cdvs: 

兴趣点检测、局部特征选择、局部特征描述、局部特征描述子聚合、局部特征描述子压缩、局部特征位置压缩

局部特征选择: 首先按照兴趣点的LoG卷积响应值和主曲率比率的概率值从大到小排序，根据排序结果筛选出前2*N个候选兴趣点；然后按照兴趣点的尺度因子的概率值进一步排序，筛选1.5N个兴趣点；最后按照兴趣点的坐标编号从小到大排序，筛选前N个兴趣点。

局部特征描述子聚合:在全局特征聚合之前，所有用于聚合的128维的局部描述子先被归一化并进行PCA降维，得到32维的降维向量。降维结束后，采用基于Fisher向量聚合方法对上述向量样本进行聚合。[Fisher向量聚合](https://www.cnblogs.com/jie-dcai/p/5740480.html)是基于一个含有512个高斯分布函数的高斯混合模型（Gaussian Mixture Model， [GMM](https://blog.csdn.net/happyer88/article/details/46576379)） 在全局描述子聚合阶段，若干高斯分布函数将被选择用于聚合。具体的高斯函数选取方法如下：首先，高斯分布函数根据均值累计梯度向量标准差的取值降序排序；随后，对于操作点限制在码流长度为512字节、1024字节及2048字节的描述子，排序靠前的k个高斯分布函数将被用于后续全局特征码流生成。选取大于某个阈值的高斯函数。选择高斯函数后，对相应的梯度向量每一维进行二值化

## WGAN

[参考](https://zhuanlan.zhihu.com/p/25071913)

- 判别器最后一层去掉sigmoid (把分类变成了回归)
- 生成器和判别器的loss不取log
- 每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c
- 不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行 （梯度本身就是不稳定的）

## 目标检测([参考](https://baijiahao.baidu.com/s?id=1598999301741831102&wfr=spider&for=pc))

1. 目前通过卷积神经网络进行检测的方法主要分为one-stage和two-stage，分别写出了解的对应的算法。

   在共性上两类检测算法有哪些差异？

   1)One-stage：yolov1、yolov2、yolov3、SSD、RetinaNet

    Two-stage：Fast R-CNN、Faster R-CNN

   2)Two-stage检测算法的共性，以faster r-cnn为例，使用了复杂的网络用于每个候选区域的分类和回归；ROI pooling后的feature channels数目较大，导致内存消耗和计算量都比较大。

   One-stage检测算法的共性，从网络结构上看只是多分类的rpn网络，相当于faster rcnn的第一阶段，因此one-stage主要的优势是速度快。其预测结果是从feature map回归出目标的位置及分类，有的也采用了anchor的概念。而two-stage对上述结果进行roi pooling后会进一步细化，因此two-stage算法检测精度一般相对较高。还有一种观点是，two-stage的rpn部分相当于做了正负样本均衡，这也是two-stage检测效果相对较好的一个原因。one-stage算法对小目标检测效果较差，如果所有的anchor都没有覆盖到这个目标，那么这个目标就会漏检。如果一个比较大的anchor覆盖了这个目标，那么较大的感受野会弱化目标的真实特征，得分也不会高。two-stage算法中的roi pooling会对目标做resize, 小目标的特征被放大，其特征轮廓也更为清晰，因此检测也更为准确。
   
2. R-CNN

   1. 输入一张图片，通过指定算法从图片中提取 2000 个类别独立的候选区域（可能目标区域）SS（slective search） 很耗时
   2. 对于每个候选区域利用卷积神经网络来获取一个特征向量 耗时
   3. 对于每个区域相应的特征向量，利用支持向量机SVM 进行分类，并通过一个bounding box regression调整目标包围框的大小。三个东西分别训练 耗时
   
3. Fast-RCNN

   1. 首先还是采用selective search提取2000个候选框RoI

   2. 使用一个卷积神经网络对全图进行特征提取

   3. 使用一个RoI Pooling Layer在全图特征上摘取每一个RoI对应的特征

   4. 分别经过为21和84维的全连接层（并列的，前者是分类输出，后者是回归输出）

     总结： Fast R-CNN通过CNN直接获取整张图像的特征图，再使用RoI Pooling Layer在特征图上获取对应每个候选框的特征，避免了R-CNN中的对每个候选框串行进行卷积（耗时较长）。但是SS这个过程还是很耗时

4. Faster-RCNN

   Faster R-CNN 取代selective search，直接通过一个Region Proposal Network (RPN)生成待检测区域，这么做，在生成RoI区域的时候，时间也就从2s缩减到了10ms。下图是Faster R-CNN整体结构。

   ![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9hZTAxLmFsaWNkbi5jb20va2YvVVRCOHRWNzJPd1F5ZGVKazQzUFVxNkF5UXBYYWsuanBn)


   由上图可知，Faster R-CNN由共享卷积层、RPN、RoI pooling以及分类和回归四部分组成：

   首先使用共享卷积层为全图提取特征feature maps
   将得到的feature maps送入RPN，RPN生成待检测框(指定RoI的位置),并对RoI的包围框进行第一次修正
   RoI Pooling Layer根据RPN的输出在feature map上面选取每个RoI对应的特征，并将维度置为定值
   使用全连接层(FC Layer)对框进行分类，并且进行目标包围框的第二次修正。
   尤其注意的是，Faster R-CNN真正实现了端到端的训练(end-to-end training)。

   Faster R-CNN中的RoI Pooling Layer与 Fast R-CNN中原理一样。在RoI Pooling Layer之后，就是Faster R-CNN的分类器和RoI边框修正训练。分类器主要是分这个提取的RoI具体是什么类别(人，车，马等)，一共C+1类(包含一类背景)。RoI边框修正和RPN中的anchor边框修正原理一样，同样也是[SmoothL1 Loss](https://blog.csdn.net/yang_daxia/article/details/91360606)。

5. MaskRCNN

   Mask R-CNN可以分解为如下的3个模块：Faster-RCNN、RoI Align和Mask。算法框架如下：

   ![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9hZTAxLmFsaWNkbi5jb20va2YvVVRCOFgyTXp2dXZKWEtKa1Nhamg3NjM3YUZYYTAucG5n)

   RoI Pooling和RoIAlign最大的区别是：前者使用了两次量化操作，而后者并没有采用量化操作，使用了线性插值算法，具体的解释如下所示。(利用利用双线性插值来估计这些蓝点，最后求max)

6. ![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9hZTAxLmFsaWNkbi5jb20va2YvVVRCOGlxcGhPSm9TZGVKazQzT3c3NjFhNFhYYVgucG5n)

   Yolo算法开创了one-stage检测的先河，它将物体分类和物体检测网络合二为一，都在全连接层完成。故它大大降低了目标检测的耗时，提高了实时性。但它的缺点也十分明显。

   每个网格只对应两个bounding box，当物体的长宽比不常见（也就是训练数据集覆盖不到时），效果很差。
   原始图片只划分为7x7的网格，当两个物体靠的很近时，效果很差
   最终每个网格只对应一个类别，容易出现漏检（物体没有被识别到）。
   对于图片中比较小的物体，效果很差。这其实是所有目标检测算法的通病，SSD对它有些优化。

7. SSD

   SSD和Yolo一样都是采用一个CNN网络来进行检测，但是却采用了多尺度的特征图.

   SSD认为目标检测中的物体，只与周围信息相关，它的感受野不是全局的，故没必要也不应该做全连接。SSD的特点如下。

   1、 每一个卷积层，都会输出不同大小感受野的feature map。在这些不同尺度的feature map上，进行目标位置和类别的训练和预测，从而达到多尺度检测的目的，可以克服yolo对于宽高比不常见的物体，识别准确率较低的问题。

   2、 在Yolo中，每个单元预测多个边界框，但是其都是相对这个单元本身（正方块），但是真实目标的形状是多变的，Yolo需要在训练过程中自适应目标的形状。而SSD和Faster R-CNN相似，也提出了anchor的概念。卷积输出的feature map，每个点对应为原图的一个区域的中心点。以这个点为中心，构造出6个宽高比例不同，大小不同的anchor（SSD中称为default box）。每个anchor对应4个位置参数(x,y,w,h)和21个类别概率（voc训练集为20分类问题，在加上anchor是否为背景，共21分类）。SSD的检测值也与Yolo不太一样。对于每个单元的每个先验框，其都输出一套独立的检测值，对应一个边界框。

   另外，SSD采用了数据增强。生成与目标物体真实box间IOU为0.1 0.3 0.5 0.7 0.9的patch，随机选取这些patch参与训练，并对他们进行随机水平翻转等操作


## [faiss](https://blog.csdn.net/kanbuqinghuanyizhang/article/details/80774609) 大规模检索

1、倒排索引：这里的索引是聚类中心。如果需要存储的向量太多，通过暴力搜索索引`IndexFlatL2`速度很慢，这里介绍一种加速搜索的方法的索引`IndexIVFFlat`。翻译过来叫倒排文件，其实是使用K-means建立聚类中心，然后通过查询最近的聚类中心，然后比较聚类中的所有向量得到相似的向量。

2、快速的KNN、[ANN](https://yongyuan.name/blog/ann-search.html)算法

### [乘积量化PQ](https://blog.csdn.net/chenyq991/article/details/78934989?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

### [IVFOPQ](https://yongyuan.name/blog/ann-search.html)

KDTree，LSH，ITQ

倒排PQ乘积量化(IVFPQ)



## 不均衡样本

### [focal loss](https://blog.csdn.net/qwer7512090/article/details/93136325)

上下采样

提前困难样本挖掘

样本不均衡怎么处理？一个batch类别均等采样，修改loss对不同样本的权重。

## 基础知识

### BP

DNN反向传播公式推导

CNN反向传播公式推导

矩阵正定性的判断,Hessian矩阵正定性在梯度下降中的应用

若矩阵所有特征值均不小于0,则判定为半正定。若矩阵所有特征值均大于0,则判定为正定。在判断优化算法的可行性时Hessian矩阵的正定性起到了很大的作用,若Hessian正定,则函数的二阶偏导恒大于0,函数的变化率处于递增状态,在牛顿法等梯度下降的方法中,Hessian矩阵的正定性可以很容易的判断函数是否可收敛到局部或全局最优解。

[拟牛顿法](https://zhuanlan.zhihu.com/p/46536960)的[原理](https://blog.csdn.net/itplus/article/details/21896453)

牛顿法的收敛速度快,迭代次数少,但是Hessian矩阵很稠密时,每次迭代的计算量很大,随着数据规模增大,Hessian矩阵也会变大,需要更多的存储空间以及计算量。拟牛顿法就是在牛顿法的基础上引入了Hessian矩阵的近似矩阵,避免了每次都计算Hessian矩阵的逆,在拟牛顿法中,用Hessian矩阵的逆矩阵来代替Hessian矩阵,虽然不能像牛顿法那样保证最优化的方向,但其逆矩阵始终是正定的,因此算法始终朝最优化的方向搜索。



### [感受野](https://blog.csdn.net/program_developer/article/details/80958716) 

定义：一个卷积核可以映射原始输入图的区域大小。 计算：![image-20200225101050685](/img/study/image-20200225101050685.png)

### tensorflow [conv2d](https://blog.csdn.net/g0415shenw/article/details/86081330)

讲下tensorflow搭建网络和训练的流程。

### pytorch [conv2d](https://ptorch.com/docs/1/torch-nn)

### [BN](https://www.cnblogs.com/eilearn/p/9780696.html)

首先，BN是用来解决“Internal Covariate Shift” 即如果ML系统实例集合<X,Y>中的输入值X的分布老是变，这不符合IID假设，网络模型很难稳定的学规律，所以我们在输入层会进行归一化，在训练过程中，因为各层参数不停在变化，所以每个隐层都会面临covariate shift的问题，即Internal Covariate Shift。所以能不能让每个隐层节点的激活输入分布固定下来呢？这样就避免了“Internal Covariate Shift”问题了，顺带解决反向传播中梯度消失问题。BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，**这样使得激活输入值落在非线性函数对输入比较敏感的区域，**使得梯度变大，加快训练速度。具体计算是在一个minibatch内，将某个神经元对应的原始的激活x通过减去mini-Batch内m个实例获得的m个激活x求得的均值E(x)并除以求得的方差Var(x)。但是如果把分布全部拉回了线性区域，去少了非线性变换，网络的表征能力会大大下降，所以BN**为了保证非线性的获得，对变换后的满足均值为0方差为1的x又进行了scale加上shift操作(y=scale\*x+shift)**，通过网络自身的学习得到这两个参数，使得分布稍微遍历中心的线性区域。

在预测阶段，**可以用从所有训练实例中获得的统计量来代替Mini-Batch里面m个训练实例获得的均值和方差统计量**，因为本来就打算用全局的统计量，只是因为计算量等太大所以才会用Mini-Batch这种简化方式的，那么在推理的时候直接用全局统计量即可。

优点：提升了训练速度，收敛过程大大加快；还能增加分类效果，提高网络的泛化能力(感觉是因为，即使训练数据与测试数据分布不同，也会通过bn将分布映射到相同的位置上)。（一种解释是这是类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果；另外调参过程也简单多了），对于初始化要求没那么高，而且可以使用大的学习率等。

### [one-hot](https://blog.csdn.net/Li_yi_chao/article/details/80852701) 

介绍one-hot，为什么采用one-hot

解决了分类器不好处理属性数据的问题，让特征之间的距离计算更加合理;在一定程度上也起到了扩充特征的作用，比如性别本身是一个特征，经过one hot编码以后，就变成了男或女两个特征;将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。



### [pooling] 意义

增大深层卷积的感受野。降维减少参数量和减少卷积后的冗余。

具有局部平移不变形，提高网络效率

### [inception](https://baijiahao.baidu.com/s?id=1601882944953788623&wfr=spider&for=pc) [xception](https://blog.csdn.net/lk3030/article/details/84847879) [VGG](https://blog.csdn.net/jyy555555/article/details/80515562) [mobilenet](https://www.cnblogs.com/dengshunge/p/11334640.html) 与xception[区别](https://blog.csdn.net/u013548568/article/details/79910669) 

mobileNet、shufflenet的原理？说了下原理。 		

​				为什么mobileNet在理论上速度很快，工程上并没有特别大的提升？ 先说了卷积源码上的实现，两个超大矩阵相乘，可能是group操作，是一些零散的卷积操作，速度会慢。（大佬觉得不满意，说应该从内存上去考虑。申请空间？确实不太清楚。）



### Flops计算：

计算flops，卷积维度变换的公式推导，卷积是如何编程实现的；

<img src="/img/study/image-20200225121221770.png" alt="image-20200225121221770" style="zoom: 67%;" /> 不考虑bias时有-1，有bias时没有-1。

输出大小计算：

 ![image-20200225121334638](/img/study/image-20200225121334638.png) 

参数量 `F*F*Cin*Cout`

9. 默写交叉熵和softmax，还有它的[BP](https://blog.csdn.net/sunlanchang/article/details/88825134) 
10. [PCA](https://blog.csdn.net/program_developer/article/details/80632779) 

### 激活函数相关

1. sigmoid函数特性

定义域为![img](https://uploadfiles.nowcoder.com/images/20190315/311436_1552619092213_171B20A604B88BE2CC570EF936359F57)

值域为(0,1)

函数在定义域内为连续和光滑的函数

处处可导,导数为![img](https://uploadfiles.nowcoder.com/images/20190315/311436_1552619110289_2FC0EF550E43398C033CAF8AE5CD23F6)

2. 讲下激活函数的意义

   增大非线性表征能力，充分组合特征。

3. 为什么要用relu而不用sigmoid

   从饱和区间、敏感区间和梯度三个方面来回答。

   第一，采用sigmoid等函数，算激活函数时（指数运算），计算量大，反向传播求误差梯度时，求导涉及除法，计算量相对大，而采用Relu激活函数，整个过程的计算量节省很多。 
   第二，对于深层网络，sigmoid函数反向传播时，很容易就会出现梯度消失的情况（在sigmoid接近饱和区时，变换太缓慢，导数趋于0，这种情况会造成信息丢失），从而无法完成深层网络的训练。 
   第三，Relu会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。

4. softplus

   softplus可以看作是ReLu的平滑y=log(1+ex)

5. 梯度消失 爆炸

   https://www.cnblogs.com/makefile/p/activation-function.html

   解决方法

   权重初始化
   使用合适的方式初始化权重, 如ReLU使用MSRA的[初始化方式](https://www.cnblogs.com/wangguchangqing/p/11013698.html), tanh使用xavier初始化方式.

   激活函数选择
   激活函数要选择ReLU等梯度累乘稳定的.

   学习率
   一种训练优化方式是对输入做白化操作(包括正规化和去相关), 目的是可以选择更大的学习率. 现代深度学习网络中常使用Batch Normalization(包括正规化步骤,但不含去相关).

### 卷积相关

卷积的实现，意义

卷积运算通过三个重要的思想来帮助改进机器学习系统：稀疏交互、参数共享、等变表示

**1\*1卷积过滤器** ,它的大小是**1\*1**，没有考虑在前一层局部信息之间的关系。最早出现在 Network In Network的论文中 ，使用1*1卷积是想加深加宽网络结构 ，在Inception网络（ Going Deeper with Convolutions ）中用来降维。还可以增加非线性和减少参数

由于3*3卷积或者5*5卷积在几百个filter的卷积层上做卷积操作时相当耗时，所以1*1卷积在3*3卷积或者5*5卷积计算之前先降低维度。



## 还需要看的

混合高斯模型

yolov2、yolov3、RetinaNet

图像预处理

1. 编码实现计算图的inference （用Java基本完整写出来了）

   